{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d2055e4-1836-4824-8ec0-12083572c11f",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "caca8ecb-666e-4693-a772-f04f1f481537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize\n",
    "import sklearn.datasets\n",
    "def load_iris_binary():\n",
    "    D, L = sklearn.datasets.load_iris()['data'].T, sklearn.datasets.load_iris()['target']\n",
    "    D = D[:, L != 0] # remove setosa from D\n",
    "    L = L[L!=0] # remove setosa from L\n",
    "    L[L==2] = 0 # We assign label 0 to virginica (was label 2)\n",
    "    return D, L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81296454-225e-4a34-b904-8631f4351dd4",
   "metadata": {},
   "source": [
    "## Implementation of L-BFGS algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cddea5d-f362-4117-b988-a7d33e945f55",
   "metadata": {},
   "source": [
    "I define an example function f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "d093c103-8e12-4d15-815b-c88f12bd0d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    y = x[0]\n",
    "    z = x[1]\n",
    "    return (y+3)**2 + np.sin(y) + (z+1)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d785fe31-d635-4a2a-80ad-6d70335b3c8c",
   "metadata": {},
   "source": [
    "Now i call the funcion of scipy.optimize to apply the L-BFGS algorithm. With the parameter approx_grad=True i am saying that the gradient is automatically obtained through finite differences method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "7c670eb9-67dd-462a-a403-684034acbfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, f, d = scipy.optimize.fmin_l_bfgs_b(func=f, x0=np.zeros(2), approx_grad = True, iprint = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "4d25fd79-a532-46f8-9773-c0335523e1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point of minimum: [-2.57747138 -0.99999927]\n"
     ]
    }
   ],
   "source": [
    "print('Point of minimum: %s'%(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "9bdec949-61dd-4662-be3b-a6116ebde5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of the minimum: -0.3561430123647649\n"
     ]
    }
   ],
   "source": [
    "print('Value of the minimum: %s'%(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "3c5336f0-bf79-4946-a0d7-e5613f65e779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 21\n"
     ]
    }
   ],
   "source": [
    "print('Number of iterations: %s'%(d['funcalls']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff01a8c7-9646-4a5f-a5cb-9f66b4c93c8e",
   "metadata": {},
   "source": [
    "By passing an explicit approximation of the gradient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "b2454f25-3857-4e59-aa02-a6510e2a1870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_grad(x):\n",
    "    y = x[0]\n",
    "    z = x[1]\n",
    "    grad_y = 2*(y+3) + np.cos(y)\n",
    "    grad_z = 2*(z+1)\n",
    "    val = (y+3)**2 + np.sin(y) + (z+1)**2\n",
    "    return val, np.array([grad_y,grad_z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "d59adc02-214d-46ee-9952-3f651b345d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, f, d = scipy.optimize.fmin_l_bfgs_b(func=f_grad, x0=np.zeros(2), approx_grad = False, iprint = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "b23abf5d-f450-497b-b8e9-6588f55f959b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point of minimum: [-2.57747137 -0.99999927]\n"
     ]
    }
   ],
   "source": [
    "print('Point of minimum: %s'%(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "86ca805e-4f05-4760-87c3-acb4f21340c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of the minimum: -0.3561430123647611\n"
     ]
    }
   ],
   "source": [
    "print('Value of the minimum: %s'%(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "9fe12524-e575-4819-bf15-936b7771e8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 7\n"
     ]
    }
   ],
   "source": [
    "print('Number of iterations: %s'%(d['funcalls']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d1ddbe-8f81-4b5b-8455-84110a3b379a",
   "metadata": {},
   "source": [
    "With this method the algorithm only performs 7 iterations instead of 21 with the same result for minimum!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd3c629-c47e-4e8a-84fb-6c77f81ecf63",
   "metadata": {},
   "source": [
    "## Binary Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "9192fc07-cbd9-4234-af55-28f0b588aac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_db_2to1(D, L, seed=0):\n",
    "    nTrain = int(D.shape[1]*2.0/3.0) # 2/3 of the dataset D are used for training, 1/3 for validation\n",
    "    np.random.seed(seed)\n",
    "    idx = np.random.permutation(D.shape[1]) # take a random array of 150 elements, each element is 0<x<=149 (np.arange(150))\n",
    "    idxTrain = idx[0:nTrain] # first 100 are indices of training samples \n",
    "    idxTest = idx[nTrain:] # remaining 50 are indices of validation samples\n",
    "    DTR = D[:, idxTrain] # D for training\n",
    "    DTE = D[:, idxTest] # D for validation\n",
    "    LTR = L[idxTrain] # L for training\n",
    "    LTE = L[idxTest] # L for validation\n",
    "    return (DTR, LTR), (DTE, LTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "717416db-ba67-486a-a94c-0f5a526b9325",
   "metadata": {},
   "outputs": [],
   "source": [
    "D, L = load_iris_binary()\n",
    "(DTR, LTR), (DTE, LTE) = split_db_2to1(D, L)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da8fc40-a11f-4322-9efe-ff45e0be8fbd",
   "metadata": {},
   "source": [
    "In the dataset there are only samples belonging to class virginica and versicolor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec64f2f-1f3b-462a-a5db-b262d45a2f6f",
   "metadata": {},
   "source": [
    "We want to optimize the function $J(w,b) = \\frac{\\lambda}{2}||w||^2 + \\frac{1}{n}\\sum_{i=1}^{n} log(1+e^{-z_i (w^T x_i + b)})$ with \n",
    " $ z_i =\n",
    "  \\begin{cases}\n",
    "    1       & \\quad \\text{if } c_i = 1 \\\\\n",
    "    -1  & \\quad \\text{if } c_i = 0\n",
    "  \\end{cases}\n",
    " $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "2f7c4bd1-f505-4da2-8b65-164da47472c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class logRegClass:\n",
    "    def __init__(self, DTR, LTR, l):\n",
    "        self.DTR = DTR\n",
    "        self.LTR = LTR\n",
    "        self.l = l\n",
    "        \n",
    "    def __compute_zi(self, ci):\n",
    "        return 2*ci-1\n",
    "    \n",
    "    def logreg_obj(self, v): # still works if DTR is one sample only? yes but it must be of shape (4,1)\n",
    "        w, b = v[0:-1], v[-1]\n",
    "        J = l/2*(np.linalg.norm(w)**2)\n",
    "        summary = 0\n",
    "        for i in range(self.DTR.shape[1]):\n",
    "            xi = self.DTR[:,i:i+1]\n",
    "            ci = self.LTR[i]\n",
    "            zi = self.__compute_zi(ci)\n",
    "            summary += np.logaddexp(0,-zi*(np.dot(w.T,xi)+b))\n",
    "        J += (1/self.DTR.shape[1]) * summary\n",
    "        return J\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "7a11025f-6781-452a-823b-dc0c4a49aa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 4 # dimensionality of the feature space\n",
    "l = 10**-6\n",
    "logRegObj = logRegClass(DTR, LTR, l)\n",
    "x, f, d = scipy.optimize.fmin_l_bfgs_b(func=logRegObj.logreg_obj, \n",
    "                                       x0=np.zeros(DTR.shape[0]+1), \n",
    "                                       approx_grad = True, \n",
    "                                       iprint = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "d28b298a-ecfa-4587-81d1-804dd7e5adf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point of minimum: [ 14.87051718  -9.39021566 -29.49339455 -88.83860813 231.12771345]\n"
     ]
    }
   ],
   "source": [
    "print('Point of minimum: %s'%(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "e418e126-0ecd-4ba6-b7cb-547c847d1496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of the minimum: [0.0075415]\n"
     ]
    }
   ],
   "source": [
    "print('Value of the minimum: %s'%(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "fb3e5855-70a5-484f-9770-4b3ac3e67339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 372\n"
     ]
    }
   ],
   "source": [
    "print('Number of iterations: %s'%(d['funcalls']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37042308-91c8-4302-9b8a-a986b48ce19d",
   "metadata": {},
   "source": [
    "Now we can compute the predictions according to the model parameters w,b that we have obtained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "8f497df8-681c-45d9-adfb-d384099d5cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate with lambda=0.000001 is: 11.764705882352944%\n"
     ]
    }
   ],
   "source": [
    "w, b = x[0:-1], x[-1]\n",
    "S=np.zeros((DTE.shape[1]))\n",
    "for i in range(DTE.shape[1]):\n",
    "    xi = DTE[:,i:i+1]\n",
    "    s = np.dot(w.T,xi)+b\n",
    "    S[i] = s\n",
    "LP = S>0\n",
    "acc = sum(LP == LTE)/len(LTE)\n",
    "err = 1 - acc\n",
    "print('Error rate with lambda=%f is: %s%%'%(l,err*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b11457-d765-4c8e-b311-11377a710738",
   "metadata": {},
   "source": [
    "## Multiclass Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b2779d-110e-4974-972d-5ec975434ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
