{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29534d77-6595-4003-8d8f-49cbd74c003f",
   "metadata": {},
   "source": [
    "# SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c141f31a-de2e-441b-8625-1499923b1df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize\n",
    "import scipy.special\n",
    "import sklearn.datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "def load_iris_binary():\n",
    "    D, L = sklearn.datasets.load_iris()['data'].T, sklearn.datasets.load_iris()['target']\n",
    "    D = D[:, L != 0] # remove setosa from D\n",
    "    L = L[L!=0] # remove setosa from L\n",
    "    L[L==2] = 0 # We assign label 0 to virginica (was label 2)\n",
    "    return D, L\n",
    "def load_iris():\n",
    "    D, L = sklearn.datasets.load_iris()['data'].T, sklearn.datasets.load_iris()['target']\n",
    "    return D, L\n",
    "def split_db_2to1(D, L, seed=0):\n",
    "    nTrain = int(D.shape[1]*2.0/3.0) # 2/3 of the dataset D are used for training, 1/3 for validation\n",
    "    np.random.seed(seed)\n",
    "    idx = np.random.permutation(D.shape[1]) # take a random array of 150 elements, each element is 0<x<=149 (np.arange(150))\n",
    "    idxTrain = idx[0:nTrain] # first 100 are indices of training samples \n",
    "    idxTest = idx[nTrain:] # remaining 50 are indices of validation samples\n",
    "    DTR = D[:, idxTrain] # D for training\n",
    "    DTE = D[:, idxTest] # D for validation\n",
    "    LTR = L[idxTrain] # L for training\n",
    "    LTE = L[idxTest] # L for validation\n",
    "    return (DTR, LTR), (DTE, LTE)\n",
    "D, L = load_iris_binary()\n",
    "(DTR, LTR), (DTE, LTE) = split_db_2to1(D, L)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4fb684-ba67-4fb1-b7e7-56fa0ac4f6b7",
   "metadata": {},
   "source": [
    "## Solution to the reformulated dual SVM (without bias term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b4b850a0-8c10-4fae-a651-3af9462d74c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = DTR.shape[1]\n",
    "F = DTR.shape[0]\n",
    "K = 1\n",
    "C = 10\n",
    "# Compute the labels z\n",
    "LTRz = np.zeros(N)\n",
    "for i in range(N):\n",
    "    LTRz[i] = 1 if LTR[i]==1 else -1\n",
    "LTEz = np.zeros(len(LTE))\n",
    "for i in range(len(LTE)):\n",
    "    LTEz[i] = 1 if LTE[i]==1 else -1\n",
    "      \n",
    "# Compute the expaded feature space D_ \n",
    "D_ = np.vstack((DTR, K*np.ones(N)))\n",
    "\n",
    "# Compute matrix G_ of dot products of all samples of D_\n",
    "G_ = np.dot(D_.T, D_)\n",
    "\n",
    "# Compute matrix H_\n",
    "LTRz_matrix = np.dot(LTRz.reshape(-1,1), LTRz.reshape(1,-1))\n",
    "H_ = G_ * LTRz_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "97f78902-35dc-4c62-a6d4-ad4fb0665dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that represents J_D(alpha) we want to minimize\n",
    "def LDc_obj(alpha): # alpha has shape (n,)\n",
    "    n = len(alpha)\n",
    "    minusJDc = 0.5 * np.dot(np.dot(alpha.T, H_), alpha) - np.dot(alpha.T, np.ones(n)) # 1x1\n",
    "    return minusJDc, gradLDc(alpha)\n",
    "\n",
    "def gradLDc(alpha):\n",
    "    n = len(alpha)\n",
    "    return (np.dot(H_, alpha) - 1).reshape(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e0daf769-9b67-470e-aeb8-fb619f0cfe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimize LD_(alpha)\n",
    "bounds = [(0,C)] * N\n",
    "m, primal, _ = scipy.optimize.fmin_l_bfgs_b(func=LDc_obj, \n",
    "                                       bounds=bounds,\n",
    "                                       x0=np.zeros(N), factr=1.0)\n",
    "# m is the final alpha\n",
    "wc_star = np.sum(m * LTRz * D_, axis=1)\n",
    "\n",
    "# extract w and b\n",
    "w_star, b_star = wc_star[:-1], wc_star[-1]\n",
    "\n",
    "# compute the scores\n",
    "S = np.dot(w_star.T, DTE) + b_star*K # the *K is not present in slides!??\n",
    "# or: S=np.dot(wc_star.T, np.vstack((DTE, K*np.ones(DTE.shape[1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "031443cb-b755-4b2a-a426-0c801fe8cefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def primal_obj(wc_star):\n",
    "    return 0.5 * np.linalg.norm(wc_star)**2 + C * np.sum(np.maximum(0,1-LTRz * np.dot(wc_star.T, D_)))\n",
    "def duality_gap(wc_star, alpha_star):\n",
    "    return primal_obj(wc_star) + LDc_obj(alpha_star)[0]\n",
    "primal_loss = primal_obj(wc_star)\n",
    "dual_loss = LDc_obj(m)[0]\n",
    "duality_gap=primal_obj(wc_star) + LDc_obj(m)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5eaf3bab-a22e-42c7-bc57-78dbe945d035",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_labels = np.where(S > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9b588b1b-d5ec-427b-aa42-3bb0fc3dc926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=10.0, K=1, Primal loss: 78.968950, Dual loss: -78.968928, Duality gap: 0.000021876, Error rate: 5.9%\n"
     ]
    }
   ],
   "source": [
    "acc = sum(predict_labels == LTE) / len(predict_labels)\n",
    "print('C=%.1f, K=%d, Primal loss: %f, Dual loss: %f, Duality gap: %.9f, Error rate: %.1f%%'%(C,K,primal_loss,dual_loss,duality_gap,(1-acc)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136edf0d-aaea-4b3e-8b8e-9b34f0233d7d",
   "metadata": {},
   "source": [
    "## Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "7aea2143-2e49-41f7-b2b2-d4f4710c5ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.        , 1.10539922, 1.88692044, ..., 1.06925223, 1.28938422,\n",
       "        1.03508435],\n",
       "       [1.10539922, 2.        , 1.17377394, ..., 1.12245643, 1.19204991,\n",
       "        1.09255058],\n",
       "       [1.88692044, 1.17377394, 2.        , ..., 1.10539922, 1.39851904,\n",
       "        1.06521929],\n",
       "       ...,\n",
       "       [1.06925223, 1.12245643, 1.10539922, ..., 2.        , 1.73344696,\n",
       "        1.63128365],\n",
       "       [1.28938422, 1.19204991, 1.39851904, ..., 1.73344696, 2.        ,\n",
       "        1.43604929],\n",
       "       [1.03508435, 1.09255058, 1.06521929, ..., 1.63128365, 1.43604929,\n",
       "        2.        ]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = eps = 1\n",
    "c=1\n",
    "d=2\n",
    "C = 1\n",
    "gamma=1\n",
    "#ker = kernel(DTR, DTR, 'Polynomial', eps, c, d)\n",
    "ker = kernel(DTR, DTR, 'RBF', eps, gamma)\n",
    "H_ = LTRz_matrix * ker\n",
    "ker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "613abb71-de0b-42f7-85c5-fc3f6f60cfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel(X1, X2, kernelType, *params):\n",
    "    eps = params[0]\n",
    "    kernel = 0;\n",
    "    if kernelType == 'Polynomial':\n",
    "        c = params[1]\n",
    "        d = params[2]\n",
    "        kernel = (np.dot(X1.T, X2) + c)**d\n",
    "    elif kernelType == 'RBF':\n",
    "        gamma = params[1]       \n",
    "        x = np.repeat(X1, X2.shape[1], axis=1)\n",
    "        y = np.tile(X2, X1.shape[1])\n",
    "        kernel = np.exp(-gamma * np.linalg.norm(x-y, axis=0).reshape(X1.shape[1],X2.shape[1])**2)\n",
    "    return kernel + eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3489960e-e854-46a9-9ae1-9766291b60ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LDc_obj(alpha): # alpha has shape (n,)\n",
    "    n = len(alpha)\n",
    "    minusJDc = 0.5 * np.dot(np.dot(alpha.T, H_), alpha) - np.dot(alpha.T, np.ones(n)) # 1x1\n",
    "    return minusJDc, gradLDc(alpha)\n",
    "\n",
    "def gradLDc(alpha):\n",
    "    n = len(alpha)\n",
    "    return (np.dot(H_, alpha) - 1).reshape(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8d12b720-a88b-4a37-afcf-7e71afccb78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=1.0, K=sqrt(eps)=1, Dual loss: -11.978133, Error rate: 8.8%\n"
     ]
    }
   ],
   "source": [
    "bounds = [(0,C)] * N\n",
    "m, primal, _ = scipy.optimize.fmin_l_bfgs_b(func=LDc_obj, \n",
    "                                            bounds=bounds,\n",
    "                                            x0=np.zeros(N), \n",
    "                                            factr=1.0)\n",
    "wc_star = np.sum(m * LTRz * D_, axis=1)\n",
    "w_star, b_star = wc_star[:-1], wc_star[-1]\n",
    "#S = np.sum(np.dot((m*LTRz).reshape(1,-1), kernel(DTR,DTE,'Polynomial', eps, c, d)), axis=0)\n",
    "S = np.sum(np.dot((m*LTRz).reshape(1,-1), kernel(DTR,DTE,'RBF', eps, gamma)), axis=0)\n",
    "dual_loss = LDc_obj(m)[0]\n",
    "predict_labels = np.where(S > 0, 1, 0)\n",
    "acc = sum(predict_labels == LTE) / len(predict_labels)\n",
    "print('C=%.1f, K=sqrt(eps)=%d, Dual loss: %f, Error rate: %.1f%%'%(C,K,dual_loss,(1-acc)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "77799005-1750-41a8-a911-0e86920322fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.        , -1.10539922,  1.88692044, ..., -1.06925223,\n",
       "        -1.28938422, -1.03508435],\n",
       "       [-1.10539922,  2.        , -1.17377394, ...,  1.12245643,\n",
       "         1.19204991,  1.09255058],\n",
       "       [ 1.88692044, -1.17377394,  2.        , ..., -1.10539922,\n",
       "        -1.39851904, -1.06521929],\n",
       "       ...,\n",
       "       [-1.06925223,  1.12245643, -1.10539922, ...,  2.        ,\n",
       "         1.73344696,  1.63128365],\n",
       "       [-1.28938422,  1.19204991, -1.39851904, ...,  1.73344696,\n",
       "         2.        ,  1.43604929],\n",
       "       [-1.03508435,  1.09255058, -1.06521929, ...,  1.63128365,\n",
       "         1.43604929,  2.        ]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a3a2b88d-ffa8-4c42-85e7-2ddb4ac9540d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66,)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c6a912-d8bd-4063-a88e-4042f6f5cabc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
