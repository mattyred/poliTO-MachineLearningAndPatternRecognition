{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29534d77-6595-4003-8d8f-49cbd74c003f",
   "metadata": {},
   "source": [
    "# SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c141f31a-de2e-441b-8625-1499923b1df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize\n",
    "import scipy.special\n",
    "import sklearn.datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "def load_iris_binary():\n",
    "    D, L = sklearn.datasets.load_iris()['data'].T, sklearn.datasets.load_iris()['target']\n",
    "    D = D[:, L != 0] # remove setosa from D\n",
    "    L = L[L!=0] # remove setosa from L\n",
    "    L[L==2] = 0 # We assign label 0 to virginica (was label 2)\n",
    "    return D, L\n",
    "def load_iris():\n",
    "    D, L = sklearn.datasets.load_iris()['data'].T, sklearn.datasets.load_iris()['target']\n",
    "    return D, L\n",
    "def split_db_2to1(D, L, seed=0):\n",
    "    nTrain = int(D.shape[1]*2.0/3.0) # 2/3 of the dataset D are used for training, 1/3 for validation\n",
    "    np.random.seed(seed)\n",
    "    idx = np.random.permutation(D.shape[1]) # take a random array of 150 elements, each element is 0<x<=149 (np.arange(150))\n",
    "    idxTrain = idx[0:nTrain] # first 100 are indices of training samples \n",
    "    idxTest = idx[nTrain:] # remaining 50 are indices of validation samples\n",
    "    DTR = D[:, idxTrain] # D for training\n",
    "    DTE = D[:, idxTest] # D for validation\n",
    "    LTR = L[idxTrain] # L for training\n",
    "    LTE = L[idxTest] # L for validation\n",
    "    return (DTR, LTR), (DTE, LTE)\n",
    "D, L = load_iris_binary()\n",
    "(DTR, LTR), (DTE, LTE) = split_db_2to1(D, L)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4fb684-ba67-4fb1-b7e7-56fa0ac4f6b7",
   "metadata": {},
   "source": [
    "## Solution to the reformulated dual SVM (without bias term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "b4b850a0-8c10-4fae-a651-3af9462d74c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = DTR.shape[1]\n",
    "F = DTR.shape[0]\n",
    "K = 1\n",
    "C = 10\n",
    "# Compute the labels z\n",
    "LTRz = np.zeros(N)\n",
    "for i in range(N):\n",
    "    LTRz[i] = 1 if LTR[i]==1 else -1\n",
    "    \n",
    "# Compute the expaded feature space D_ \n",
    "D_ = np.vstack((DTR, K*np.ones(N)))\n",
    "\n",
    "# Compute matrix G_ of dot products of all samples of D_\n",
    "G_ = np.dot(D_.T, D_)\n",
    "\n",
    "# Compute matrix H_\n",
    "LTRz_matrix = np.dot(LTRz.reshape(-1,1), LTRz.reshape(1,-1))\n",
    "H_ = G_ * LTRz_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "97f78902-35dc-4c62-a6d4-ad4fb0665dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that represents J_D(alpha) we want to minimize\n",
    "def LDc_obj(alpha): # alpha has shape (n,)\n",
    "    n = len(alpha)\n",
    "    minusJDc = 0.5 * np.dot(np.dot(alpha.T, H_), alpha) - np.dot(alpha.T, np.ones(n)) # 1x1\n",
    "    gradLDc = gradLD_(alpha)\n",
    "    return minusJDc, gradLDc\n",
    "\n",
    "def gradLDc(alpha):\n",
    "    n = len(alpha)\n",
    "    return (np.dot(H_, alpha) - 1).reshape(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "e0daf769-9b67-470e-aeb8-fb619f0cfe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimize LD_(alpha)\n",
    "bounds = [(0,C)] * N\n",
    "m, primal, _ = scipy.optimize.fmin_l_bfgs_b(func=LDc_obj, \n",
    "                                       bounds=bounds,\n",
    "                                       x0=np.zeros(N), factr=1.0)\n",
    "# m is the final alpha\n",
    "wc_star = np.sum(m * LTRz * D_, axis=1)\n",
    "\n",
    "# extract w and b\n",
    "w_star, b_star = wc_star[:-1], wc_star[-1]\n",
    "\n",
    "# compute the scores\n",
    "S = np.dot(w_star.T, DTE) + b_star*K # the *K is not present in slides!??\n",
    "# or: S=np.dot(wc_star.T, np.vstack((DTE, K*np.ones(DTE.shape[1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "031443cb-b755-4b2a-a426-0c801fe8cefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def primal_obj(wc_star):\n",
    "    return 0.5 * np.linalg.norm(wc_star)**2 + C * np.sum(np.maximum(0,1-LTRz * np.dot(wc_star.T, D_)))\n",
    "def duality_gap(wc_star, alpha_star):\n",
    "    return primal_obj(wc_star) + LDc_obj(alpha_star)[0]\n",
    "primal_loss = primal_obj(wc_star)\n",
    "dual_loss = LDc_obj(m)[0]\n",
    "duality_gap=primal_obj(wc_star) + LDc_obj(m)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "5eaf3bab-a22e-42c7-bc57-78dbe945d035",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_labels = np.where(S > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "9b588b1b-d5ec-427b-aa42-3bb0fc3dc926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=10.0, K=1, Primal loss: 78.968950, Dual loss: -78.968928, Duality gap: 0.000021876, Error rate: 5.9%\n"
     ]
    }
   ],
   "source": [
    "acc = sum(predict_labels == LTE) / len(predict_labels)\n",
    "print('C=%.1f, K=%d, Primal loss: %f, Dual loss: %f, Duality gap: %.9f, Error rate: %.1f%%'%(C,K,primal_loss,dual_loss,duality_gap,(1-acc)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381de9d5-f31e-4432-8eb3-08ab802ee117",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
