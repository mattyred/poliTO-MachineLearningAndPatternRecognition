{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "772fcb37-e3cf-4c68-b5e4-910371cb7c3c",
   "metadata": {},
   "source": [
    "## MVG Gaussian Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2a58a59b-8bf7-4276-be31-2feb7a1f3543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets\n",
    "def load_iris():\n",
    "    D, L = sklearn.datasets.load_iris()['data'].T, sklearn.datasets.load_iris()['target']\n",
    "    return D, L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c680977-27d6-43a6-85f7-d48c1dc50523",
   "metadata": {},
   "outputs": [],
   "source": [
    "D, L = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca7062a5-5849-4a78-b2cd-6626b17abc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_db_2to1(D, L, seed=0):\n",
    "    nTrain = int(D.shape[1]*2.0/3.0) # 2/3 of the dataset D are used for training, 1/3 for validation\n",
    "    np.random.seed(seed)\n",
    "    idx = np.random.permutation(D.shape[1]) # take a random array of 150 elements, each element is 0<x<=149 (np.arange(150))\n",
    "    idxTrain = idx[0:nTrain] # first 100 are indices of training samples \n",
    "    idxTest = idx[nTrain:] # remaining 50 are indices of validation samples\n",
    "    DTR = D[:, idxTrain] # D for training\n",
    "    DTE = D[:, idxTest] # D for validation\n",
    "    LTR = L[idxTrain] # L for training\n",
    "    LTE = L[idxTest] # L for validation\n",
    "    return (DTR, LTR), (DTE, LTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "349a74a4-c95e-45ff-888e-c327f840f1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(DTR, LTR), (DTE, LTE) = split_db_2to1(D, L)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b19ab44-ee0b-469a-9ecd-43969ead6a03",
   "metadata": {},
   "source": [
    "Now we have to compute the ML solution. First we compute the empirical mean and variance for each class label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bea202c-eb1d-43d0-88b5-cfd0720167ce",
   "metadata": {},
   "source": [
    "The training phase consists in computing the empirical class mean and the empirical class covariance matrix given the training samples DTR. Here we're fitting a normal distribution to our training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00e412b3-a61b-4de2-8eac-08fec3e88305",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_classes = [] # list of empiracal mean for each class\n",
    "cov_classes = [] # list of covariance matrix for each class\n",
    "for i in set(LTR):\n",
    "    DTR_class_i = DTR[:,LTR==i]\n",
    "    N_class_i = DTR_class_i.shape[1]\n",
    "    mu_class_i = DTR_class_i.mean(axis=1).reshape(-1,1)\n",
    "    cov_class_i = 1/N_class_i * np.dot(DTR_class_i-mu_class_i, (DTR_class_i-mu_class_i).T)\n",
    "    mu_classes.append(mu_class_i)\n",
    "    cov_classes.append(cov_class_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94a7d69-9358-41ed-af34-06f162884b4f",
   "metadata": {},
   "source": [
    "The test phase consists in computing the normal density for each testing sample, thus the probability for each test sample to belong to either class 0 or 1 or 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db69955d-d7d7-4d48-9272-5e09fe533f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logpdf_GAU_ND_1sample(x,mu,C):\n",
    "    M = x.shape[0] # num of features of sample x\n",
    "    mu = mu.reshape(M,1) # mean of the sample\n",
    "    xc = x - mu # x centered\n",
    "    invC = np.linalg.inv(C)\n",
    "    _,log_abs_detC = np.linalg.slogdet(C)\n",
    "    return -M/2 * np.log(2*np.pi) - 1/2 * log_abs_detC - 1/2 * np.dot(np.dot(xc.T,invC),xc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f3a5722-204a-4022-ad49-f7cc7eb9e78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = np.zeros(shape=(3,DTE.shape[1]))\n",
    "for i in range(DTE.shape[1]):\n",
    "    xt = DTE[:,i:i+1] # test sample xt\n",
    "    # now compute the probability density related to each class label for the sample xt\n",
    "    score = np.zeros(shape=(3,1))\n",
    "    for j in set(LTE):\n",
    "        mu = mu_classes[j]\n",
    "        C = cov_classes[j]\n",
    "        score[j,:] = np.exp(logpdf_GAU_ND_1sample(xt,mu,C))\n",
    "    S[:,i:i+1] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4e4efac-58b0-4e66-8070-eae105e15885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.661338147750939e-15\n"
     ]
    }
   ],
   "source": [
    "SJoint = 1/3 * S # assuming that the prior probability is 1/3 for each class\n",
    "SJoint_sol = np.load('Solution/SJoint_MVG.npy')\n",
    "print(np.abs(SJoint_sol - SJoint).max()) # test if it's correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6028d989-97ba-4b2c-adf0-d1adca57e46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SMarginal = SJoint.sum(0).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e2d285d7-c604-4eb1-950c-b4d4aff44a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPost = np.zeros((3,50))\n",
    "for c in range(3):\n",
    "    SJoint_c = SJoint[c,:].reshape(-1,1)\n",
    "    SPost_c = (SJoint_c / SMarginal).reshape(1,-1)\n",
    "    SPost[c,:] = SPost_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b4c90792-b9ba-47f3-abd1-47859fa2ec22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate 4.000000%\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = np.argmax(SPost,axis=0)\n",
    "corrected_assigned_labels = LTE==predicted_labels\n",
    "acc = sum(corrected_assigned_labels) / len(LTE)\n",
    "err = 1-acc\n",
    "print('Error rate %f%%' % (err * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba3ff99-58e1-4672-ae2b-3a1af8c2e386",
   "metadata": {},
   "source": [
    "Using logarithms calculus to avoid numerical issues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cfa630dc-a05e-42be-af39-eec31520c5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logSJoint = np.log(SJoint) + np.log(1/3)\n",
    "logSMarginal = scipy.special.logsumexp(logSJoint, axis=0).reshape(1,-1)\n",
    "log_SPost = logSJoint - logSMarginal  \n",
    "SPost_ = np.exp(log_SPost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e280c24e-9f9f-4401-ae08-b6ac860ce7b8",
   "metadata": {},
   "source": [
    "Decision boundaries(extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0e30abe0-111b-4e3c-94c1-a5a3dad914e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25086505, 0.06955017, 0.17238754, 0.06294118],\n",
       "       [0.06955017, 0.07653979, 0.06442907, 0.03588235],\n",
       "       [0.17238754, 0.06442907, 0.20934256, 0.08764706],\n",
       "       [0.06294118, 0.03588235, 0.08764706, 0.04941176]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DTE_1 = DTE[:, LTE==1]\n",
    "mu_1 = np.mean(DTE_1,axis=1).reshape(-1,1)\n",
    "DTE_1_centered = DTE_1 - mu_1\n",
    "N1 = np.shape(DTE_1)[1]\n",
    "C1 = 1/N1 * np.dot(DTE_1_centered, DTE_1_centered.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "01b90783-b58c-45c3-a16b-630a8e6e6d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.91359315, -0.54840466,  2.50507376,  0.96343653],\n",
       "       [-0.54840466,  0.57451284, -1.90285012, -0.71907121],\n",
       "       [ 2.50507376, -1.90285012,  7.7332271 ,  2.9452322 ],\n",
       "       [ 0.96343653, -0.71907121,  2.9452322 ,  1.13      ]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DTE_0 = DTE[:, LTE==0]\n",
    "mu_0 = np.mean(DTE_0,axis=1).reshape(-1,1)\n",
    "DTE_0_centered = DTE_0 - mu_1\n",
    "N0 = np.shape(DTE_0)[1]\n",
    "C0 = 1/N0 * np.dot(DTE_0_centered, DTE_0_centered.T)\n",
    "C0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e8aa54b5-2c9b-49dd-9bf1-e8a7f11b115c",
   "metadata": {},
   "outputs": [],
   "source": [
    "V0 = C0**-1\n",
    "V1 = C1**-1\n",
    "A = -1/2*(V1-V0)\n",
    "b = np.dot(V1,mu_1) - np.dot(V0,mu_0)\n",
    "_,logabsV1 = np.linalg.slogdet(V1)\n",
    "_,logabsV0 = np.linalg.slogdet(V0)\n",
    "c = -1/2 * (np.dot(np.dot(mu_1.T,V1),mu_1) - np.dot(np.dot(mu_0.T,V0),mu_0)) + 1/2 * (logabsV1-logabsV0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c89a87a1-c2ab-4370-9e94-a3495698b779",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply PCA\n",
    "l = np.logical_or((LTE==0),(LTE==1))\n",
    "DTE10 = DTE[:,l]\n",
    "P = projection_PCA(DTE10, 2)\n",
    "y = np.dot(P.T, DTE10)\n",
    "\n",
    "#plot decision function\n",
    "def llr(xt):\n",
    "    return np.dot(np.dot(xt.T,A),xt) + np.dot(xt.T,b) + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "359cc91d-f791-4672-ab63-a65410f27ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection_PCA(X,m):\n",
    "    mu = D.mean(axis = 1).reshape(-1,1)\n",
    "    Xc = X - mu\n",
    "    K = np.shape(X)[1] # number of columns of X\n",
    "    C = 1/K * np.dot(Xc, Xc.T) # covariance matrix\n",
    "    sigma, U = np.linalg.eigh(C)\n",
    "    P = U[:, ::-1][:, 0:m] # take the m eigenvectos of C associated to the m highest eigenvalues\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab61346-ac3c-40c3-9949-33b92fa175eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
