{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "772fcb37-e3cf-4c68-b5e4-910371cb7c3c",
   "metadata": {},
   "source": [
    "## Importing the IRIS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a58a59b-8bf7-4276-be31-2feb7a1f3543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets\n",
    "def load_iris():\n",
    "    D, L = sklearn.datasets.load_iris()['data'].T, sklearn.datasets.load_iris()['target']\n",
    "    return D, L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c680977-27d6-43a6-85f7-d48c1dc50523",
   "metadata": {},
   "outputs": [],
   "source": [
    "D, L = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca7062a5-5849-4a78-b2cd-6626b17abc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_db_2to1(D, L, seed=0):\n",
    "    nTrain = int(D.shape[1]*2.0/3.0) # 2/3 of the dataset D are used for training, 1/3 for validation\n",
    "    np.random.seed(seed)\n",
    "    idx = np.random.permutation(D.shape[1]) # take a random array of 150 elements, each element is 0<x<=149 (np.arange(150))\n",
    "    idxTrain = idx[0:nTrain] # first 100 are indices of training samples \n",
    "    idxTest = idx[nTrain:] # remaining 50 are indices of validation samples\n",
    "    DTR = D[:, idxTrain] # D for training\n",
    "    DTE = D[:, idxTest] # D for validation\n",
    "    LTR = L[idxTrain] # L for training\n",
    "    LTE = L[idxTest] # L for validation\n",
    "    return (DTR, LTR), (DTE, LTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "349a74a4-c95e-45ff-888e-c327f840f1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(DTR, LTR), (DTE, LTE) = split_db_2to1(D, L)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b19ab44-ee0b-469a-9ecd-43969ead6a03",
   "metadata": {},
   "source": [
    "Now we have to compute the ML solution. First we compute the empirical mean and variance for each class label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bea202c-eb1d-43d0-88b5-cfd0720167ce",
   "metadata": {},
   "source": [
    "The training phase consists in computing the empirical class mean and the empirical class covariance matrix given the training samples DTR. Here we're fitting a normal distribution to our training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "00e412b3-a61b-4de2-8eac-08fec3e88305",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_classes = [] # list of empiracal mean for each class\n",
    "cov_classes = [] # list of covariance matrix for each class\n",
    "for i in set(LTR):\n",
    "    DTR_class_i = DTR[:,LTR==i]\n",
    "    N_class_i = DTR_class_i.shape[1]\n",
    "    mu_class_i = DTR_class_i.mean(axis=1).reshape(-1,1)\n",
    "    cov_class_i = 1/N_class_i * np.dot(DTR_class_i-mu_class_i, (DTR_class_i-mu_class_i).T)\n",
    "    mu_classes.append(mu_class_i)\n",
    "    cov_classes.append(cov_class_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94a7d69-9358-41ed-af34-06f162884b4f",
   "metadata": {},
   "source": [
    "The test phase consists in computing the normal density for each testing sample, thus the probability for each test sample to belong to either class 0 or 1 or 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db69955d-d7d7-4d48-9272-5e09fe533f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logpdf_GAU_ND_1sample(x,mu,C):\n",
    "    M = x.shape[0] # num of features of sample x\n",
    "    mu = mu.reshape(M,1) # mean of the sample\n",
    "    xc = x - mu # x centered\n",
    "    invC = np.linalg.inv(C)\n",
    "    _,log_abs_detC = np.linalg.slogdet(C)\n",
    "    return -M/2 * np.log(2*np.pi) - 1/2 * log_abs_detC - 1/2 * np.dot(np.dot(xc.T,invC),xc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3f3a5722-204a-4022-ad49-f7cc7eb9e78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = np.zeros(shape=(3,DTE.shape[1]))\n",
    "for i in range(DTE.shape[1]):\n",
    "    xt = DTE[:,i:i+1] # test sample xt\n",
    "    # now compute the probability density related to each class label for the sample xt\n",
    "    score = np.zeros(shape=(3,1))\n",
    "    for j in set(LTE):\n",
    "        mu = mu_classes[j]\n",
    "        C = cov_classes[j]\n",
    "        score[j,:] = np.exp(logpdf_GAU_ND_1sample(xt,mu,C))\n",
    "    S[:,i:i+1] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a4e4efac-58b0-4e66-8070-eae105e15885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.661338147750939e-15\n"
     ]
    }
   ],
   "source": [
    "SJoint = 1/3 * S # assuming that the prior probability is 1/3 for each class\n",
    "SJoint_sol = np.load('Solution/SJoint_MVG.npy')\n",
    "print(np.abs(SJoint_sol - SJoint).max()) # test if it's correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6028d989-97ba-4b2c-adf0-d1adca57e46e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0., -0., -0., -0.,  0.,  0.,  0., -0., -0., -0.,  0., -0.,\n",
       "        -0., -0., -0., -0., -0., -0., -0., -0., -0.,  0.,  0., -0.,  0.,\n",
       "        -0., -0., -0., -0., -0., -0., -0., -0.,  0., -0., -0., -0.,  0.,\n",
       "        -0., -0., -0., -0., -0.,  0.,  0., -0., -0., -0.,  0.],\n",
       "       [-0.,  0., -0.,  0., -0.,  0.,  0.,  0.,  0., -0.,  0.,  0., -0.,\n",
       "         0., -0., -0., -0., -0.,  0.,  0.,  0., -0.,  0., -0., -0.,  0.,\n",
       "         0., -0., -0., -0.,  0.,  0., -0., -0.,  0., -0.,  0.,  0.,  0.,\n",
       "        -0., -0., -0., -0.,  0.,  0.,  0., -0.,  0., -0.,  0.],\n",
       "       [ 0., -0.,  0.,  0.,  0., -0.,  0., -0.,  0., -0., -0., -0., -0.,\n",
       "        -0.,  0.,  0.,  0., -0.,  0.,  0., -0.,  0.,  0.,  0.,  0., -0.,\n",
       "        -0.,  0.,  0.,  0.,  0.,  0., -0., -0., -0.,  0.,  0., -0.,  0.,\n",
       "        -0.,  0.,  0.,  0., -0., -0., -0.,  0., -0.,  0.,  0.]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d285d7-c604-4eb1-950c-b4d4aff44a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
